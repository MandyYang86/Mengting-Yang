{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)Collect all of the external links (there must be some on the page of your )\n",
    "2)Associate the link with a textual description of it from the website.\n",
    "3)Write a function to check whether the link is valid.\n",
    "4)Save the external links(urls), textual description, a boolean for valid, and the last vaild datetime check to an excel file.\n",
    "\n",
    "Assignments 1 - Web Scraper\n",
    "Name: Mengting Yang\n",
    "Web Link:https://www.economist.com/sections/economics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "External Link: http://www.1843magazine.com   Title:-- 1843 Magazine Valid:-- 301 Time:-- 15:10:59\n",
      "External Link: http://www.theworldin.com/   Title:-- The World In Valid:-- valid Time:-- 15:11:00\n",
      "External Link: https://learning.ly   Title:-- Learning.ly Valid:-- valid Time:-- 15:11:02\n",
      "External Link: https://www.corporatenetwork.com   Title:-- The Economist Corporate Network Valid:-- 302 Time:-- 15:11:04\n",
      "External Link: https://learning.ly   Title:-- Learning.ly Valid:-- valid Time:-- 15:11:05\n",
      "External Link: https://www.corporatenetwork.com   Title:-- The Economist Corporate Network Valid:-- 302 Time:-- 15:11:05\n",
      "External Link: https://docs.google.com/forms/d/1ZCdwituoyhHAPKjCKvDvzRp66zwOv23GrCPH4rGINrE/viewform?entry.506806900=anbo-o011   Title:-- Leave feedback Valid:-- 301 Time:-- 15:11:05\n",
      "External Link: http://survey.usabilla.com/live/s/590039f1a34ca8e8a0c5989d?reset   Title:-- Contact us Valid:-- valid Time:-- 15:11:05\n",
      "External Link: https://www.facebook.com/TheEconomist   Title:-- None Valid:-- valid Time:-- 15:11:08\n",
      "External Link: https://twitter.com/TheEconomist   Title:-- None Valid:-- valid Time:-- 15:11:08\n",
      "External Link: https://plus.google.com/100470681032489535736/posts   Title:-- None Valid:-- valid Time:-- 15:11:09\n",
      "External Link: https://www.linkedin.com/grp/home?gid=3056216   Title:-- None Valid:-- 301 Time:-- 15:11:09\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-71c23a428c86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mscrapEco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-71c23a428c86>\u001b[0m in \u001b[0;36mscrapEco\u001b[0;34m(max_pages)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msoup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#find all links\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "#https://www.youtube.com/watch?v=sVNJOiTBi_8&index=26&list=PL6gx4Cwl9DGAcbMi1sH6oAMk4JHw91mC_\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse as urlparse\n",
    "import time\n",
    "import csv\n",
    "\n",
    "file=open('result.csv', 'w')\n",
    "f=csv.writer(file,delimiter=',',quotechar='\"')\n",
    "\n",
    "def scrapEco(max_pages):\n",
    "    page=1\n",
    "    while page<=max_pages:\n",
    "        url='https://www.economist.com/sections/economics?page='+str(page)\n",
    "        web_content=requests.get(url)\n",
    "        to_text=web_content.text\n",
    "        #transform the to_text to a beautifulsoup object because it needs special format\n",
    "        soup=BeautifulSoup(to_text,\"lxml\")\n",
    "        \n",
    "        f.writerow(['url','title','valid','time'])\n",
    "        file.flush()\n",
    "        #find all links\n",
    "        for link in soup.findAll('a'):\n",
    "            href=link.get('href')\n",
    "            if href is not None:\n",
    "                newhref=href\n",
    "                title=link.string\n",
    "                #print(newhref,'-----',title)\n",
    "                \n",
    "                #Find all external links\n",
    "                if 'http' in newhref:\n",
    "                    if 'economist' not in newhref:\n",
    "                        if 'econ' not in newhref:\n",
    "                            if 'eiu' not in newhref:\n",
    "                \n",
    "                    #print('external link',newhref,'-----',title)\n",
    "                    \n",
    "                                #Check respond status\n",
    "                                r = requests.head(newhref)\n",
    "                                status=r.status_code\n",
    "                                #print(status)\n",
    "                    \n",
    "                                if status == 200:\n",
    "                                #print(newhref,'is Valid')\n",
    "                                    valid='valid'\n",
    "                                else:\n",
    "                                #print(newhref,\"Error Code\",status)\n",
    "                                    valid=status\n",
    "                    \n",
    "                                #Check time\n",
    "                                Runtime = time.strftime(\"%H:%M:%S\")\n",
    "                                #print ('time: ',localtime)\n",
    "                                f.writerow([link['href'], link.string, valid, Runtime])\n",
    "                                file.flush()\n",
    "                    \n",
    "                                print('External Link:',newhref,'  Title:--',title,'Valid:--',valid,'Time:--',Runtime)\n",
    "                    \n",
    "        file.close()\n",
    "                    \n",
    "                   \n",
    "                    \n",
    "    #https://stackoverflow.com/questions/36742232/how-to-output-the-python-print-result-into-a-table-or-csv-format?rq=1             \n",
    "   \n",
    "                \n",
    "scrapEco(1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
